{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "mnist_mlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedmagdy512/MNIST-Digit-Classifier/blob/master/MNIST_DigitClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P_-LlaWtvyu",
        "colab_type": "text"
      },
      "source": [
        "# Artificial Intelligence Nanodegree\n",
        "\n",
        "## Convolutional Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "In this notebook, we train an MLP to classify images from the MNIST database.\n",
        "\n",
        "### 1. Load MNIST Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGbrSv7Ftvyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f2cdcffe-2fcd-4c67-d34c-e42a32c34182"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# use Keras to import pre-shuffled MNIST database\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\n",
        "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "The MNIST database has a training set of 60000 examples.\n",
            "The MNIST database has a test set of 10000 examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MmUqgkCtvyy",
        "colab_type": "text"
      },
      "source": [
        "### 2. Visualize the First Six Training Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60mtsRqJtvyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "cefeeeca-bd78-46ff-cabb-3c43458f4c85"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "fig= plt.figure(figsize=(20,20))\n",
        "for i in range (6):\n",
        "  ax=fig.add_subplot(1,6,i+1)\n",
        "  ax.imshow(X_train[i],cmap='gray')\n",
        "  ax.set_title(y_train[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAADOCAYAAACpdxJrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQAT+H/s+EURBMOoEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x1440 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eachdamFtvy3",
        "colab_type": "text"
      },
      "source": [
        "### 4. Rescale the Images by Dividing Every Pixel in Every Image by 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiBhkwbDtvy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rescale [0,255] --> [0,1]\n",
        "X_train=X_train.astype('float32')/255\n",
        "X_test=X_test.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyayfkiRtvy5",
        "colab_type": "text"
      },
      "source": [
        "### 5. Encode Categorical Integer Labels Using a One-Hot Scheme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwL2qgAvtvy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "27ab8268-ca84-4acd-b2fd-6f8976dd8456"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "# print first ten (integer-valued) training labels\n",
        "print('Integer-valued labels:')\n",
        "print(y_train[:10])\n",
        "\n",
        "# one-hot encode the labels\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# print first ten (one-hot) training labels\n",
        "print('One-hot labels:')\n",
        "print(y_train[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Integer-valued labels:\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "One-hot labels:\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3dkifEJtvy8",
        "colab_type": "text"
      },
      "source": [
        "### 6. Define the Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r219Q7wYtvy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "817da495-ff45-4227-ff81-35ab2c07e38b"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# summarize the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 01:27:36.399577 140578591057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0904 01:27:36.458742 140578591057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 01:27:36.488483 140578591057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0904 01:27:36.506914 140578591057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0904 01:27:36.520101 140578591057792 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5RZrSYvtvy_",
        "colab_type": "text"
      },
      "source": [
        "### 7. Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSvvU5IWtvy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "23d422ce-ead1-4b68-abda-c01935a8a6f1"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0904 01:27:41.791718 140578591057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0904 01:27:41.823192 140578591057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR_E1UH0tvzD",
        "colab_type": "text"
      },
      "source": [
        "### 8. Calculate the Classification Accuracy on the Test Set (Before Training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZtMtWqptvzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb8f6701-5b8a-4ced-99ed-15296701b8b1"
      },
      "source": [
        "# evaluate test accuracy\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "# print test accuracy\n",
        "print('Test accuracy: %.4f%%' % accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 10.2400%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNHrfNRtvzH",
        "colab_type": "text"
      },
      "source": [
        "### 9. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrthTVfZtvzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "cf6d368c-8684-4e8e-b9a8-46b45c9c8de9"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "Checkpoint=ModelCheckpoint(verbose=1,save_best_only=True,filepath='mnist.model.best.hdf5')\n",
        "hist=model.fit(X_train,y_train,batch_size=128,epochs=10,validation_split=0.2,shuffle=True,verbose=1,callbacks=[Checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0904 01:27:48.842785 140578591057792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 8s 164us/step - loss: 0.2787 - acc: 0.9131 - val_loss: 0.1224 - val_acc: 0.9628\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.12242, saving model to mnist.model.best.hdf5\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 7s 154us/step - loss: 0.1111 - acc: 0.9661 - val_loss: 0.0931 - val_acc: 0.9722\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.12242 to 0.09313, saving model to mnist.model.best.hdf5\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.0806 - acc: 0.9758 - val_loss: 0.0992 - val_acc: 0.9727\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.09313\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0625 - acc: 0.9810 - val_loss: 0.0883 - val_acc: 0.9763\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.09313 to 0.08829, saving model to mnist.model.best.hdf5\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 8s 165us/step - loss: 0.0521 - acc: 0.9846 - val_loss: 0.0928 - val_acc: 0.9771\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.08829\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 8s 164us/step - loss: 0.0424 - acc: 0.9872 - val_loss: 0.1015 - val_acc: 0.9753\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.08829\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.0380 - acc: 0.9883 - val_loss: 0.0908 - val_acc: 0.9782\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.08829\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.1008 - val_acc: 0.9791\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.08829\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0311 - acc: 0.9907 - val_loss: 0.1079 - val_acc: 0.9782\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.08829\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.0279 - acc: 0.9918 - val_loss: 0.1050 - val_acc: 0.9787\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.08829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC-DmxBCtvzL",
        "colab_type": "text"
      },
      "source": [
        "### 10. Load the Model with the Best Classification Accuracy on the Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AUQUphWtvzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the weights that yielded the best validation accuracy\n",
        "model.load_weights('mnist.model.best.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT6PTtgFtvzN",
        "colab_type": "text"
      },
      "source": [
        "### 11. Calculate the Classification Accuracy on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yx6gYeMtvzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92b614a0-0d93-4158-fe64-f09916fb75b2"
      },
      "source": [
        "# evaluate test accuracy\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "# print test accuracy\n",
        "print('Test accuracy: %.4f%%' % accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 97.7600%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}